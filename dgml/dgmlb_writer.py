from __future__ import annotations
import io, struct, sys
from typing import Dict, List, Tuple, Any

# This file has been generated by GPT-5. I designed the format (dgmlb.h), but
# implementing the writer is finnicky and annoying and I gain little by doing it myself.
# The code is pretty horrible, I think, but I got it to work in an hour or so, which is much
# faster than doing it myself and I get to focus on more important things.

# ---------- on-disk constants (must match your C header) ----------

LE = "<"  # little-endian

# node types (uint32 on disk)
DGMLB_NODE_TYPE_INVALID = 0
DGMLB_NODE_TYPE_CHOICE = 1
DGMLB_NODE_TYPE_GOTO = 2
DGMLB_NODE_TYPE_IF = 3
DGMLB_NODE_TYPE_RAND = 4
DGMLB_NODE_TYPE_RUN = 5
DGMLB_NODE_TYPE_SAY = 6

# bytecode ops (uint32 on disk)
OP_INVALID = 0
OP_PUSH_BOOL = 1
OP_PUSH_INT = 2
OP_PUSH_FLOAT = 3
OP_PUSH_STRING = 4
OP_GET_VAR = 5
OP_SET_VAR = 6
OP_NOT = 7
OP_ADD = 8
OP_SUB = 9
OP_MUL = 10
OP_DIV = 11
OP_OR = 12
OP_AND = 13
OP_LT = 14
OP_LE = 15
OP_GT = 16
OP_GE = 17
OP_EQ = 18
OP_NE = 19

# header: char magic[8]; u32 file_size; then 4 spans (sections, speaker_ids, env_variables, env_markup)
HDR_SIZE = 8 + 4 + (8 * 5)  # 44 bytes

# struct formats
SPAN_FMT = LE + "II"  # offset, count
STRING_LEN = LE + "I"  # length (u32)
BYTECODE_FMT = LE + "II"  # op(u32), param(u32)

# on-disk structs formats
SECTION_FMT = (
    LE + "III I"
)  # name_str(off) u32, nodes.offset u32, nodes.count u32, entry_node u32
# Node: matches your struct (order preserved)
NODE_FMT = LE + "IIII I I I I I I I"  # see pack_node() for fields/comment
OPTION_FMT = (
    LE + "II I I"
)  # cond.offset/cond.count, line_id_str, text.offset/count, dest(u32)
TEXTFRAG_FMT = LE + "I I I"  # str(off), tags.offset/tags.count, type(u32)
KV_FMT = LE + "II"  # key_str(off), value_str(off)
ENVVAR_FMT = LE + "I I I"  # name(off), type(u32), default_value(u32) (see notes)
MARKUP_FMT = LE + "I I"  # name(off), parameter(off)

# ---------- helpers ----------


def align(b: io.BytesIO, multiple: int) -> None:
    pad = (-b.tell()) & (multiple - 1)
    if pad:
        b.write(b"\x00" * pad)


class StringInterner:
    """Dedup strings and assign file-relative offsets to dgml_string blobs."""

    def __init__(self):
        self._map: Dict[str, int] = {}  # str -> offset
        self._order: List[str] = []  # stable order for emission

    def intern(self, s: str) -> str:
        assert s is not None
        if s not in self._map:
            self._map[s] = -1  # placeholder; set later
            self._order.append(s)
        return s

    def emit(self, b: io.BytesIO, base_offset: int) -> Dict[str, int]:
        """Write all strings to the file and return {str: absolute_offset}."""
        # Keep 4-byte alignment for each string's header (uint32 length)
        offmap: Dict[str, int] = {}
        for s in self._order:
            align(b, 4)
            off = base_offset + b.tell()
            offmap[s] = off
            # write dgml_string {u32 length; char data[length+1]}
            data = s.encode("utf-8")
            b.write(struct.pack(STRING_LEN, len(data)))
            b.write(data)
            b.write(b"\x00")  # null terminator
        # store back
        for s, off in offmap.items():
            self._map[s] = off
        return offmap

    def offset_of(self, s: str) -> int:
        return self._map[s]


def u32(v: int) -> int:
    if v < 0 or v > 0xFFFFFFFF:
        raise ValueError("u32 out of range")
    return v


# ---------- expression compiler (from your expr_to_json output) ----------

BIN_OP = {
    "add": OP_ADD,
    "sub": OP_SUB,
    "mul": OP_MUL,
    "div": OP_DIV,
    "or": OP_OR,
    "and": OP_AND,
    "lt": OP_LT,
    "le": OP_LE,
    "gt": OP_GT,
    "ge": OP_GE,
    "eq": OP_EQ,
    "ne": OP_NE,
}


def compile_expr(expr: Any, S: StringInterner) -> List[Tuple[int, int]]:
    """
    expr is the dict produced by expr_to_json().
    returns list of (op, param) pairs.
    """
    if expr is None:
        return []
    t = expr["type"]
    out: List[Tuple[int, int]] = []

    if t.startswith("unary_"):
        op = t[len("unary_") :]
        out += compile_expr(expr["rhs"], S)
        if op == "not":
            out.append((OP_NOT, 0))
        elif op == "neg":
            # unary -x => PUSH_INT(0); SWAP? we don't have SWAP; just emit 0 - x:
            out.append((OP_PUSH_INT, 0))
            out.append((OP_SUB, 0))
        else:
            raise ValueError(f"unsupported unary op {op}")

    elif t.startswith("binary_"):
        op = t[len("binary_") :]
        out += compile_expr(expr["lhs"], S)
        out += compile_expr(expr["rhs"], S)
        bc = BIN_OP.get(op)
        if not bc:
            raise ValueError(f"unsupported binary op {op}")
        out.append((bc, 0))

    elif t == "variable":
        out.append((OP_GET_VAR, u32(S.offset_of(S.intern(expr["name"])))))

    elif t.startswith("literal_"):
        v = expr["value"]
        if t == "literal_bool":
            out.append((OP_PUSH_BOOL, 1 if v else 0))
        elif t == "literal_int":
            out.append((OP_PUSH_INT, u32(v & 0xFFFFFFFF)))
        elif t == "literal_float":
            # bit-cast python float to IEEE-754 single
            import math

            f32 = struct.pack(LE + "f", float(v))
            out.append((OP_PUSH_FLOAT, struct.unpack(LE + "I", f32)[0]))
        elif t == "literal_str":
            out.append((OP_PUSH_STRING, u32(S.offset_of(S.intern(v)))))
        else:
            raise ValueError(f"unsupported literal {t}")

    elif t == "assign":
        # compile RHS, then SET_VAR name
        out += compile_expr(expr["value"], S)
        out.append((OP_SET_VAR, u32(S.offset_of(S.intern(expr["name"])))))
    else:
        raise ValueError(f"unknown expr node type {t}")

    return out


def emit_bytecode(b: io.BytesIO, code: List[Tuple[int, int]]) -> Tuple[int, int]:
    """Returns (offset, count) in elements (dgml_byte_code)."""
    align(b, 4)
    off = b.tell()
    for op, param in code:
        b.write(struct.pack(BYTECODE_FMT, u32(op), u32(param)))
    count = len(code)
    return (off, count)


# ---------- text fragments ----------


def kv_list_from_tags(
    tags_dict: Dict[str, str], S: StringInterner
) -> List[Tuple[int, int]]:
    # returns list of (key_off, value_off)
    out = []
    for k, v in (tags_dict or {}).items():
        out.append((S.offset_of(S.intern(k)), S.offset_of(S.intern(v))))
    return out


def compile_text(
    text_list: List[Dict[str, Any]], S: StringInterner, buf: io.BytesIO
) -> Tuple[int, int]:
    """
    text_list is from your text_to_json(): each fragment has {"tags": {...}, "text": "..."} or {"variable": "..."}.
    Emits:
      - KV pairs array for each fragment (contiguously in one global KV pool),
      - TEXTFRAG array (contiguously).
    Returns span (offset,count) of TEXTFRAGs for this text.
    """
    align(buf, 4)
    frag_off = buf.tell()
    frag_count = 0

    kv_arrays: List[Tuple[int, int]] = []  # (kv_off, kv_count)
    kv_positions_before = buf.tell()

    # weâ€™ll emit KV arrays inline before each TEXTFRAG set to keep code simple.
    # alternative is a dedicated KV pool, but this avoids backpatching.

    temp_frag_records: List[
        Tuple[int, int, int]
    ] = []  # (str_off, kv_off, kv_count, type)
    # But we need to know string offsets now (we do).
    # Let's first write all KV arrays, then write TEXTFRAGs.

    kv_blocks: List[Tuple[int, int]] = []
    for frag in text_list:
        tags = frag.get("tags") or {}
        # emit KV array for this fragment
        align(buf, 4)
        kv_off = buf.tell()
        kv_count = 0
        for k, v in tags.items():
            if v is not None:
                v_offset = S.offset_of(S.intern(v))
            else:
                v_offset = S.offset_of(S.intern(""))
            buf.write(struct.pack(KV_FMT, u32(S.offset_of(S.intern(k))), u32(v_offset)))
            kv_count += 1
        kv_blocks.append((kv_off, kv_count))

    align(buf, 4)
    tf_off = buf.tell()

    # Now emit TEXTFRAGs
    for i, frag in enumerate(text_list):
        align(buf, 4)
        # text or variable
        if "text" in frag:
            s_off = S.offset_of(S.intern(frag["text"]))
            type_u32 = 0  # text
        else:
            s_off = S.offset_of(S.intern(frag["variable"]))
            type_u32 = 1  # variable
        kv_off, kv_count = kv_blocks[i]
        buf.write(struct.pack(TEXTFRAG_FMT, u32(s_off), u32(kv_off), u32(kv_count)))
        buf.write(
            struct.pack(LE + "I", u32(type_u32))
        )  # ensure type right after (already in fmt)
        frag_count += 1

    # Return span of the TEXTFRAG array we just wrote
    return (tf_off, frag_count)  # already element-aligned


# ---------- main writer ----------


def write_binary(data: Dict[str, Any], out_path: str) -> None:
    """
    data: the dict you already build in main().
    out_path: file to write.
    """
    S = StringInterner()
    S.intern("")

    # 1) Intern all strings up front
    # build_id, speakers
    for sp in data.get("speaker_ids", []):
        S.intern(sp)

    env = data.get("environment", {}) or {}
    # environment variables (best-effort schema)
    env_vars = []
    for var in env.get("variables", []):
        S.intern(var["name"])
        vtype = var.get("type", "").lower()
        if vtype == "string" and isinstance(var.get("default"), str):
            S.intern(var["default"])
        env_vars.append((var["name"], var))

    env_markup = []
    for m in env.get("markup", []) or []:
        name = m.get("name", "")
        param = m.get("parameter", "")
        S.intern(name)
        S.intern(param)
        env_markup.append((name, param))

    # sections & nodes
    sections = data["sections"]
    # Intern section names, node ids, speakers, line ids, text strings, tag keys/vals, variable names, etc.
    for sec_name, sec in sections.items():
        S.intern(sec_name)
        nodes = sec["nodes"]
        for node_id, n in nodes.items():
            S.intern(node_id)
            # node-level tags (dict or list). Weâ€™ll assume dict[str,str] or list[str]
            tags = n.get("tags") or {}
            if isinstance(tags, dict):
                for k, v in tags.items():
                    S.intern(k)
                    S.intern(str(v))
            elif isinstance(tags, list):
                for t in tags:
                    S.intern(t)

            t = n["type"]
            if t == "say":
                S.intern(n["speaker_id"])
                line = n["line"]
                if "line_id" in line and line["line_id"]:
                    S.intern(line["line_id"])
                for frag in line["text"]:
                    if "text" in frag:
                        S.intern(frag["text"])
                    if "variable" in frag:
                        S.intern(frag["variable"])
                    for k, v in (frag.get("tags") or {}).items():
                        S.intern(k)
                        if v is not None:
                            S.intern(v)
                        else:
                            S.intern("")
                if n.get("next"):
                    S.intern(str(n["next"]))
            elif t == "choice":
                for opt in n["options"]:
                    line = opt["line"]
                    if "line_id" in line and line["line_id"]:
                        S.intern(line["line_id"])
                    for frag in line["text"]:
                        if "text" in frag:
                            S.intern(frag["text"])
                        if "variable" in frag:
                            S.intern(frag["variable"])
                        for k, v in (frag.get("tags") or {}).items():
                            S.intern(k)
                            S.intern(v)
                    if "cond" in opt:
                        _ = collect_expr_strings(opt["cond"], S)
                    S.intern(str(opt["dest"]))
            elif t == "if":
                _ = collect_expr_strings(n["cond"], S)
                S.intern(str(n["true_dest"]))
                S.intern(str(n["false_dest"]))
            elif t == "goto":
                S.intern(str(n["dest"]))
            elif t == "rand":
                for d in n["nodes"]:
                    S.intern(str(d))
            elif t == "run":
                _ = collect_expr_strings(n["code"], S)
                if n.get("next"):
                    S.intern(str(n["next"]))

    # 2) Build numeric indices for node ids per-section
    index_per_section: Dict[str, Dict[str, int]] = {}
    for sec_name, sec in sections.items():
        nodes = list(sec["nodes"].keys())
        idxmap = {nid: i for i, nid in enumerate(nodes)}
        index_per_section[sec_name] = idxmap

    # 3) Start writing
    out = io.BytesIO()
    # header placeholder
    out.write(b"\x00DGMLB01")  # magic[8] (you wrote comment "D G M L B 0 1")
    out.write(b"\x00\x00\x00\x00")  # file_size placeholder
    # 4 spans placeholders (strings, sections, speaker_ids, env_variables, env_markup)
    spans_pos = out.tell()
    out.write(b"\x00" * (8 * 5))

    # Emit strings first to get definitive string offsets
    align(out, 4)
    strings_off = out.tell()
    S.emit(out, 0)  # offsets are absolute from file start
    strings_size = out.tell() - strings_off

    # Emit speaker_ids as array of dgml_stroff (u32 offsets)
    def write_u32_array(vals: List[int]) -> Tuple[int, int]:
        align(out, 4)
        off = out.tell()
        for v in vals:
            out.write(struct.pack(LE + "I", u32(v)))
        return (off, len(vals))

    speaker_span_off, speaker_count = 0, 0
    if data.get("speaker_ids"):
        speaker_offsets = [S.offset_of(s) for s in data["speaker_ids"]]
        speaker_off, speaker_count = write_u32_array(speaker_offsets)
        speaker_span_off = speaker_off

    # Emit environment
    envvar_off, envvar_count = 0, 0
    if env_vars:
        align(out, 4)
        envvar_off = out.tell()
        for name, spec in env_vars:
            t = spec.get("type", "").lower()
            if t == "bool":
                ty = 1
                dv = 1 if spec.get("default") else 0
            elif t == "int":
                ty = 2
                dv = int(spec.get("default", 0)) & 0xFFFFFFFF
            elif t == "float":
                ty = 3
                f32 = struct.pack(LE + "f", float(spec.get("default", 0.0)))
                dv = struct.unpack(LE + "I", f32)[0]
            elif t == "string":
                ty = 4
                dv = S.offset_of(S.intern(str(spec.get("default", ""))))
            else:
                ty = 0
                dv = 0
            out.write(
                struct.pack(
                    ENVVAR_FMT, u32(S.offset_of(S.intern(name))), u32(ty), u32(dv)
                )
            )
            envvar_count += 1

    markup_off, markup_count = 0, 0
    if env_markup:
        align(out, 4)
        markup_off = out.tell()
        for name, param in env_markup:
            out.write(
                struct.pack(
                    MARKUP_FMT,
                    u32(S.offset_of(S.intern(name))),
                    u32(S.offset_of(S.intern(param))),
                )
            )
            markup_count += 1

    # Emit sections + nodes + choice/text/kvs/bytecode in one pass
    sections_off = 0
    sections_count = len(sections)
    align(out, 4)
    sections_off = out.tell()

    # We'll need to backpatch section.node span after nodes are emitted.
    sec_records: List[
        Tuple[int, str]
    ] = []  # (file_offset_of_section_record, section_name)

    for sec_name, sec in sections.items():
        entry_nid = sec.get("start_node")
        entry_idx = index_per_section[sec_name][entry_nid] if entry_nid else 0
        name_off = S.offset_of(sec_name)

        # placeholder section
        out.write(
            struct.pack(
                SECTION_FMT,
                u32(name_off),
                u32(0),  # nodes.offset
                u32(0),  # nodes.count
                u32(entry_idx),
            )
        )
        sec_records.append((out.tell() - struct.calcsize(SECTION_FMT), sec_name))

    # Emit per-section nodes and related arrays; then patch section spans.
    node_offsets_per_section: Dict[str, Tuple[int, int]] = {}

    for sec_off, sec_name in sec_records:
        sec_dict = sections[sec_name]
        node_ids = list(sec_dict["nodes"].keys())
        nodemap = index_per_section[sec_name]
        nodes = [sec_dict["nodes"][nid] for nid in node_ids]

        node_count = 0
        nodes_buf = io.BytesIO()

        for i, n in enumerate(nodes):
            t = n["type"]
            # common fields
            id_off = S.offset_of(node_ids[i])
            section_idx = 0  # your header has section_idx in node; you also store section_idx in section. We'll put 0.
            # node tags: you defined node.tags as span of dgml_stroff; if yours is dict, keep just the keys
            node_tags = n.get("tags") or {}
            node_tag_list = (
                list(node_tags.keys())
                if isinstance(node_tags, dict)
                else list(node_tags)
            )
            tag_off, tag_count = (
                write_u32_array([S.offset_of(S.intern(t)) for t in node_tag_list])
                if node_tag_list
                else (0, 0)
            )

            # bytecode (if/run/choice conds)
            code_off, code_count = 0, 0
            choice_off, choice_count = 0, 0
            rand_off, rand_count = 0, 0
            text_off, text_count = 0, 0
            say_speaker_off = 0
            line_id_off = 0
            dest = 0xFFFFFFFF
            if_true_dest = 0xFFFFFFFF
            if_false_dest = 0xFFFFFFFF
            node_type = DGMLB_NODE_TYPE_INVALID

            if t == "say":
                node_type = DGMLB_NODE_TYPE_SAY
                say_speaker_off = u32(S.offset_of(S.intern(n["speaker_id"])))
                # line
                line = n["line"]
                if line.get("line_id"):
                    line_id_off = u32(S.offset_of(S.intern(line["line_id"])))
                # text fragments
                text_off, text_count = compile_text(line["text"], S, out)
                # next
                if n.get("next") and n["next"] != "end":
                    dest = u32(nodemap[n["next"]])

            elif t == "choice":
                node_type = DGMLB_NODE_TYPE_CHOICE
                opts = n["options"]
                # Emit bytecode/text into the main stream, but keep the option records contiguous
                options_buf = io.BytesIO()
                for opt in opts:
                    cond = compile_expr(opt.get("cond"), S)
                    cond_off, cond_count = emit_bytecode(out, cond) if cond else (0, 0)
                    line = opt["line"]
                    lid = line.get("line_id")
                    # Offsets use 0 as "invalid". Only node indices use 0xFFFFFFFF.
                    lid_off = (
                        u32(S.offset_of(S.intern(lid)))
                        if lid
                        else u32(S.offset_of(S.intern("")))
                    )
                    tf_off, tf_count = compile_text(line["text"], S, out)
                    dst = (
                        u32(nodemap[opt["dest"]])
                        if opt["dest"] != "end"
                        else 0xFFFFFFFF
                    )
                    options_buf.write(
                        struct.pack(
                            OPTION_FMT,
                            u32(cond_off),
                            u32(cond_count),
                            u32(lid_off),
                            u32(tf_off),
                        )
                    )
                    options_buf.write(struct.pack(LE + "I", u32(tf_count)))
                    options_buf.write(struct.pack(LE + "I", u32(dst)))
                align(out, 4)
                choice_off = out.tell()
                out.write(options_buf.getvalue())
                choice_count = len(opts)

            elif t == "goto":
                node_type = DGMLB_NODE_TYPE_GOTO
                dest = u32(nodemap[n["dest"]]) if n["dest"] != "end" else 0xFFFFFFFF

            elif t == "rand":
                node_type = DGMLB_NODE_TYPE_RAND
                ids = [u32(nodemap[d]) for d in n["nodes"] if d != "end"]
                rand_off, rand_count = write_u32_array(ids) if ids else (0, 0)

            elif t == "if":
                node_type = DGMLB_NODE_TYPE_IF
                code = compile_expr(n["cond"], S)
                code_off, code_count = emit_bytecode(out, code)
                if_true_dest = (
                    u32(nodemap[n["true_dest"]])
                    if n["true_dest"] != "end"
                    else 0xFFFFFFFF
                )
                if_false_dest = (
                    u32(nodemap[n["false_dest"]])
                    if n["false_dest"] != "end"
                    else 0xFFFFFFFF
                )

            elif t == "run":
                node_type = DGMLB_NODE_TYPE_RUN
                code = compile_expr(n["code"], S)
                code_off, code_count = emit_bytecode(out, code)
                if n.get("next") and n["next"] != "end":
                    dest = u32(nodemap[n["next"]])

            else:
                raise SystemExit(f"unknown node type {t}")

            # Pack node into a temporary contiguous buffer to avoid interleaving with side data
            nodes_buf.write(struct.pack(LE + "I", u32(id_off)))
            nodes_buf.write(struct.pack(LE + "I", u32(say_speaker_off)))
            nodes_buf.write(struct.pack(SPAN_FMT, u32(tag_off), u32(tag_count)))
            nodes_buf.write(struct.pack(SPAN_FMT, u32(code_off), u32(code_count)))
            nodes_buf.write(struct.pack(SPAN_FMT, u32(choice_off), u32(choice_count)))
            nodes_buf.write(struct.pack(SPAN_FMT, u32(rand_off), u32(rand_count)))
            nodes_buf.write(struct.pack(SPAN_FMT, u32(text_off), u32(text_count)))
            nodes_buf.write(struct.pack(LE + "I", u32(section_idx)))
            nodes_buf.write(struct.pack(LE + "I", u32(dest)))
            nodes_buf.write(struct.pack(LE + "I", u32(if_true_dest)))
            nodes_buf.write(struct.pack(LE + "I", u32(if_false_dest)))
            nodes_buf.write(struct.pack(LE + "I", u32(node_type)))

            node_count += 1

        # Now write the contiguous nodes block and patch the sectionâ€™s nodes span
        align(out, 4)
        nodes_off = out.tell()
        out.write(nodes_buf.getvalue())

        cur = out.tell()
        # name at +0, nodes.offset at +4, nodes.count at +8
        out.seek(sec_off + 4)
        out.write(struct.pack(LE + "I", u32(nodes_off)))
        out.write(struct.pack(LE + "I", u32(node_count)))
        out.seek(cur)

        node_offsets_per_section[sec_name] = (nodes_off, node_count)

    # 4) Backpatch header spans and file size
    file_size = out.tell()
    out.seek(8)  # after magic
    out.write(struct.pack(LE + "I", u32(file_size)))

    out.seek(spans_pos)
    # strings span
    out.write(struct.pack(SPAN_FMT, u32(strings_off), u32(strings_size)))
    # sections span
    out.write(struct.pack(SPAN_FMT, u32(sections_off), u32(sections_count)))
    # speaker_ids span
    out.write(struct.pack(SPAN_FMT, u32(speaker_span_off), u32(speaker_count)))
    # env_variables span
    out.write(struct.pack(SPAN_FMT, u32(envvar_off), u32(envvar_count)))
    # env_markup span
    out.write(struct.pack(SPAN_FMT, u32(markup_off), u32(markup_count)))

    # 5) Write to disk
    with open(out_path, "wb") as f:
        f.write(out.getvalue())


# ---------- helpers to gather strings from expr trees ----------


def collect_expr_strings(expr: Any, S: StringInterner) -> None:
    if not expr:
        return
    t = expr["type"]
    if t.startswith("binary_"):
        collect_expr_strings(expr["lhs"], S)
        collect_expr_strings(expr["rhs"], S)
    elif t.startswith("unary_"):
        collect_expr_strings(expr["rhs"], S)
    elif t == "variable":
        S.intern(expr["name"])
    elif t == "assign":
        S.intern(expr["name"])
        collect_expr_strings(expr["value"], S)
    elif t.startswith("literal_"):
        v = expr["value"]
        if t == "literal_str":
            S.intern(v)
    # others: ints/bools/floats donâ€™t add strings
